# ğŸš— Documentation ComplÃ¨te du Projet Car Price Prediction MLOps Pipeline

## ğŸ“‹ Table des MatiÃ¨res

1. [Vue d'Ensemble](#-vue-densemble)
2. [Architecture du SystÃ¨me](#ï¸-architecture-du-systÃ¨me)
3. [Technologies UtilisÃ©es](#ï¸-technologies-utilisÃ©es)
4. [Structure du Projet](#-structure-du-projet)
5. [Configuration et Installation](#ï¸-configuration-et-installation)
6. [Pipeline de DonnÃ©es](#-pipeline-de-donnÃ©es)
7. [ModÃ¨le de Machine Learning](#-modÃ¨le-de-machine-learning)
8. [Orchestration avec Airflow](#-orchestration-avec-airflow)
9. [Tracking avec MLflow](#-tracking-avec-mlflow)
10. [Services et Ports](#-services-et-ports)
11. [Utilisation](#-utilisation)
12. [Monitoring et Reporting](#-monitoring-et-reporting)
13. [Troubleshooting](#-troubleshooting)
14. [DÃ©ploiement en Production](#-dÃ©ploiement-en-production)

---

## ğŸ¯ Vue d'Ensemble

Ce projet implÃ©mente un **pipeline MLOps complet** pour la prÃ©diction des prix des voitures au Maroc. Il automatise l'ensemble du cycle de vie du machine learning, de la collecte des donnÃ©es jusqu'au dÃ©ploiement en production.

### Objectifs Principaux

- âœ… **Automatisation complÃ¨te** du pipeline ML (entraÃ®nement, Ã©valuation, dÃ©ploiement)
- âœ… **TraÃ§abilitÃ©** de tous les modÃ¨les et expÃ©riences avec MLflow
- âœ… **Orchestration robuste** des tÃ¢ches avec Apache Airflow
- âœ… **Containerisation** pour la reproductibilitÃ© avec Docker
- âœ… **Promotion automatique** des modÃ¨les (None â†’ Staging â†’ Production)
- âœ… **Monitoring** et reporting automatisÃ©
- âœ… **Interface Web** interactive avec Streamlit
- âœ… **Tests unitaires** et intÃ©gration continue

### FonctionnalitÃ©s ClÃ©s

---

## ğŸ—ï¸ Architecture du SystÃ¨me

### Infrastructure Docker

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Docker Compose Stack                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   Airflow    â”‚  â”‚   MLflow     â”‚  â”‚  PostgreSQL  â”‚      â”‚
â”‚  â”‚  Webserver   â”‚  â”‚   Server     â”‚  â”‚   (Airflow)  â”‚      â”‚
â”‚  â”‚  :8080       â”‚  â”‚   :5050      â”‚  â”‚   :54322     â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   Airflow    â”‚  â”‚   Airflow    â”‚  â”‚  PostgreSQL  â”‚      â”‚
â”‚  â”‚  Scheduler   â”‚  â”‚  Triggerer   â”‚  â”‚   (MLflow)   â”‚      â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚   :54323     â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   Airflow    â”‚  â”‚   Airflow    â”‚  â”‚   Streamlit  â”‚      â”‚
â”‚  â”‚   Worker     â”‚  â”‚     Init     â”‚  â”‚     App      â”‚      â”‚
â”‚  â”‚  (Celery)    â”‚  â”‚              â”‚  â”‚   :8501      â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚              Redis (Message Broker)               â”‚       â”‚
â”‚  â”‚                  :6379                            â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flux de DonnÃ©es du Pipeline ML

```
Raw Data (CSV 24,776 lignes)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. check_data_quality       â”‚ â† Validation (4.6% missing)
---

## ğŸ› ï¸ Technologies UtilisÃ©es

### Orchestration & Workflow
- **Apache Airflow 2.9.3** - Orchestration du pipeline ML
- **Celery** - ExÃ©cution distribuÃ©e des tÃ¢ches
- **Redis 7.2** - Message broker pour Celery
---

## ğŸ“ Structure du Projet

```
PythonProject9/
â”œâ”€â”€ README.md                           # Ce fichier - Documentation complÃ¨te
â”œâ”€â”€ requirements.txt                    # DÃ©pendances Python
â”œâ”€â”€ requirements-airflow.txt            # DÃ©pendances Airflow + ML
â”œâ”€â”€ params.yaml                         # HyperparamÃ¨tres du modÃ¨le
â”œâ”€â”€ docker-compose-full.yml             # Stack Docker complÃ¨te
â”œâ”€â”€ Dockerfile.airflow                  # Image custom Airflow + ML
â”œâ”€â”€ docker-start-full.sh                # Script dÃ©marrage stack
â”œâ”€â”€ docker-stop-full.sh                 # Script arrÃªt stack
â”œâ”€â”€ docker-reset-full.sh                # Script reset complet
â”‚
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â””â”€â”€ car_price_ml_pipeline.py    # DAG principal (7 tÃ¢ches)
â”‚   â”œâ”€â”€ logs/                           # Logs Airflow
â”‚   â”‚   â””â”€â”€ dag_id=car_price_predictor_pipeline/
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ airflow.cfg                 # Configuration Airflow
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train_with_mlflow.py            # Pipeline ML complet
â”‚   â”‚                                   # (CarPricePipeline class)
â”‚   â””â”€â”€ load_model_mlflow.py            # Chargement modÃ¨les
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/
â”‚       â””â”€â”€ avito_car_dataset_ALL.csv   # Dataset source (24,776 lignes)
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ car_model.pkl                   # ModÃ¨le RandomForest entraÃ®nÃ©
â”‚   â”œâ”€â”€ scaler.pkl                      # StandardScaler pour features
â”‚   â””â”€â”€ encoders.pkl                    # LabelEncoders pour catÃ©gorielles
â”‚
â”œâ”€â”€ artifacts/
â”‚   â”œâ”€â”€ feature_importance.png          # Graphique importance features
â”‚   â”œâ”€â”€ feature_importance.csv          # DonnÃ©es importance
â”‚   â”œâ”€â”€ predictions_plot.png            # PrÃ©dictions vs rÃ©el
â”‚   â”œâ”€â”€ residuals_plot.png              # Analyse des rÃ©sidus
â”‚   â”œâ”€â”€ feature_info.json               # MÃ©tadonnÃ©es features
â”‚   â””â”€â”€ price_scaler_info.json          # Info scaler prix
â”‚
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ pipeline_report_*.json          # Rapports d'exÃ©cution pipeline
â”‚
â”œâ”€â”€ mlflow/
â”‚   â””â”€â”€ mlruns/                         # Artifacts MLflow locaux
â”‚       â””â”€â”€ <experiment_id>/
â”‚           â””â”€â”€ <run_id>/
â”‚               â”œâ”€â”€ artifacts/
â”‚               â”œâ”€â”€ metrics/
â”‚               â”œâ”€â”€ params/
â”‚               â””â”€â”€ tags/
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_pipeline.py                # Tests unitaires pipeline
â”‚   â”œâ”€â”€ test_integration.py             # Tests d'intÃ©gration
â”‚   â””â”€â”€ test_car_pipeline.py            # Tests CarPricePipeline
â”‚
â””â”€â”€ main_mlflow.py                      # Application Streamlit
```

---

## âš™ï¸ Configuration et Installation

### MÃ©thode 1: Installation Docker (RecommandÃ©e - Production Ready)

#### 1. Cloner le Repository

```bash
git clone https://github.com/Azaziop/detection_car_price.git
cd detection_car_price
```

#### 2. VÃ©rifier Docker

```bash
# VÃ©rifier que Docker est installÃ© et en cours d'exÃ©cution
docker --version
docker-compose --version

# DÃ©marrer Docker Desktop si nÃ©cessaire
```

#### 3. DÃ©marrer la Stack ComplÃ¨te

```bash
# Donner les permissions d'exÃ©cution
chmod +x docker-start-full.sh docker-stop-full.sh docker-reset-full.sh

# DÃ©marrer tous les services (MLflow + Streamlit + Airflow)
./docker-start-full.sh

# Attendre 2-3 minutes que tous les services dÃ©marrent
# Suivre les logs en temps rÃ©el
docker-compose -f docker-compose-full.yml logs -f
```

#### 4. VÃ©rifier les Services

```bash
# Status de tous les services
docker-compose -f docker-compose-full.yml ps

# Les 9 services devraient Ãªtre "healthy" ou "running"
```

#### 5. AccÃ©der aux Interfaces

- **Airflow**: http://localhost:8080 (admin / airflow)
- **MLflow**: http://localhost:5050
- **Streamlit**: http://localhost:8501

### MÃ©thode 2: Installation Locale (DÃ©veloppement)

#### 1. CrÃ©er un Environnement Virtuel

**Avec Python 3.11 (recommandÃ© pour Airflow):**
```bash
# Option 1: Si Python 3.11 est installÃ© via Homebrew
python3.11 -m venv .venv

# Option 2: Si pyenv est utilisÃ©
pyenv install 3.11.7
pyenv local 3.11.7
python -m venv .venv

# Activer l'environnement
source .venv/bin/activate  # Sur Windows: .venv\Scripts\activate
```

#### 2. Installer les DÃ©pendances

```bash
# DÃ©pendances de base
pip install -r requirements.txt

# Ou pour Airflow + ML
pip install -r requirements-airflow.txt

# DÃ©veloppement (optionnel)
pip install -r requirements/requirements-dev.txt
```

#### 3. Configuration Airflow (Optionnel)

```bash
# DÃ©finir le rÃ©pertoire Airflow
export AIRFLOW_HOME=$(pwd)/airflow

# Initialiser la base de donnÃ©es
airflow db init

# CrÃ©er un utilisateur admin
airflow users create \
    --username admin \
    --firstname Admin \
    --lastname User \
    --role Admin \
    --email admin@example.com \
    --password admin

# DÃ©marrer Airflow
airflow standalone+ Feature Engineering
â”‚    - Preprocess: 7,524 rows â”‚    (27 features: 9 cat + 3 num + 15 bin)
â”‚    - Train: RandomForest    â”‚
â”‚    - MLflow: Log metrics    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. evaluate_model           â”‚ â† Fetch metrics from MLflow
â”‚    - RÂ² = 0.73              â”‚   Quality check: RÂ²â‰¥0.70 âœ…
â”‚    - RMSE = 0.52            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. promote_to_staging       â”‚ â† Transition to "Staging"
â”‚    - Find version by run_id â”‚   MLflow Model Registry
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. validate_staging_model   â”‚ â† Validate model metadata
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. promote_to_production    â”‚ â† Transition to "Production"
â”‚    - Archive old version    â”‚   Deploy new model
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. send_pipeline_report     â”‚ â† Generate JSON report
â”‚    - Aggregate all metrics  â”‚   Save to reports/
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Communication entre Services

```
Airflow Tasks â†â†’ MLflow Server (http://172.18.0.4:5000)
      â†“              â†“
   XCom Data    PostgreSQL (tracking)
      â†“              â†“
File System â†â†’ Artifacts Storage
(models, artifacts, reports)price_scaler_info.json â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Interface Streamlit        â”‚
â”‚  (main.py / main_mlflow.py) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    PrÃ©dictions
```

## ğŸ“¦ PrÃ©requis

- **Python 3.11** (recommandÃ©) ou Python 3.8-3.11
  - âš ï¸ **Python 3.12 non compatible** avec Apache Airflow sur macOS
  - Voir [PYTHON_3.11_MIGRATION.md](PYTHON_3.11_MIGRATION.md) pour migrer depuis 3.12
- pip ou conda
- Git

## ğŸš€ Installation

### 1. Cloner le repository

```bash
git clone https://github.com/Azaziop/detection_car_price.git
cd detection_car_price
```

### 2. CrÃ©er un environnement virtuel

**Avec Python 3.11 (recommandÃ© pour Airflow):**
```bash
# Option 1: Si Python 3.11 est installÃ© via Homebrew
python3.11 -m venv .venv

# Option 2: Si pyenv est utilisÃ©
pyenv install 3.11.7
pyenv local 3.11.7
python -m venv .venv

# Activer l'environnement
source .venv/bin/activate  # Sur Windows: .venv\Scripts\activate
```

**Avec Python 3.12 (limitations):**
```bash
python -m venv .venv
source .venv/bin/activate
# âš ï¸ Note: Airflow ne fonctionnera pas - voir PYTHON_3.11_MIGRATION.md
```

### 3. Installer les dÃ©pendances

```bash
pip install -r requirements/requirements.txt
```

### 4. (Optionnel) Installation pour dÃ©veloppement

```bash
pip install -r requirements/requirements-dev.txt
```

---

## ğŸ”„ Pipeline de DonnÃ©es

### Vue d'Ensemble du Pipeline

Le pipeline `CarPricePipeline` (dans `scripts/train_with_mlflow.py`) exÃ©cute 6 Ã©tapes principales:

1. **Chargement** â†’ 2. **PrÃ©traitement** â†’ 3. **Feature Engineering** â†’ 4. **EntraÃ®nement** â†’ 5. **Ã‰valuation** â†’ 6. **Sauvegarde**

### 1. Chargement des DonnÃ©es (`load_data`)

```python
def load_data(self, filepath='/opt/airflow/project/data/raw/avito_car_dataset_ALL.csv'):
    df = pd.read_csv(filepath, encoding='latin1')
    # Input: 24,776 lignes Ã— 32 colonnes
    return df
```

**CaractÃ©ristiques**:
- Source: Dataset Avito Maroc
- Format: CSV avec encodage latin1
- Colonnes: 32 (caractÃ©ristiques vÃ©hicules + prix)

### 2. PrÃ©traitement (`preprocess_data`)

#### a) Gestion des Valeurs Manquantes

```python
# CatÃ©gorielles - remplissage par mode (valeur la plus frÃ©quente)
df['Origine'] = df['Origine'].fillna(df['Origine'].mode()[0])
df['PremiÃ¨re main'] = df['PremiÃ¨re main'].fillna(df['PremiÃ¨re main'].mode()[0])
df['Ã‰tat'] = df['Ã‰tat'].fillna(df['Ã‰tat'].mode()[0])

# NumÃ©riques - remplissage par mÃ©diane
df['Nombre de portes'] = df['Nombre de portes'].fillna(df['Nombre de portes'].median())
df['Puissance fiscale'] = df['Puissance fiscale'].fillna(df['Puissance fiscale'].median())

# Features binaires - remplissage par 0 (non Ã©quipÃ©)
binary_features = ['Jantes aluminium', 'Airbags', 'Climatisation', ...]
for col in binary_features:
    df[col] = df[col].fillna(0)
```

#### b) Suppression des Doublons

```python
df = df.drop_duplicates()
# RÃ©duction: 24,776 â†’ ~24,500 lignes
```

#### c) DÃ©tection et Suppression des Outliers (IQR Method)

```python
# MÃ©thode Interquartile Range
Q1 = df[numeric_cols].quantile(0.25)
Q3 = df[numeric_cols].quantile(0.75)
IQR = Q3 - Q1

lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Filtrage des outliers
for col in numeric_cols:
    df = df[(df[col] >= lower_bound[col]) & (df[col] <= upper_bound[col])]

# RÃ©sultat final: ~7,524 lignes (donnÃ©es propres)
```

#### d) Suppression de Colonnes Inutiles

```python
# Colonnes Ã  supprimer
drop_cols = ['Unnamed: 0', 'Lien', 'Secteur']
df = df.drop(columns=drop_cols, errors='ignore')
```

### 3. Feature Engineering (`prepare_features`)

#### Features NumÃ©riques (3)
- **AnnÃ©e-ModÃ¨le**: Age du vÃ©hicule (transformÃ© en annÃ©es depuis fabrication)
- **KilomÃ©trage**: Distance parcourue
- **Puissance fiscale**: Puissance du moteur

```python
numeric_features = ['AnnÃ©e-ModÃ¨le', 'KilomÃ©trage', 'Puissance fiscale']
```

#### Features CatÃ©gorielles (9) - Label Encoding
```python
categorical_features = [
    'Marque',              # Constructeur (Dacia, Renault, Peugeot, ...)
    'ModÃ¨le',              # ModÃ¨le du vÃ©hicule
    'Type de carburant',   # Essence, Diesel, Hybride, Ã‰lectrique
    'Boite de vitesses',   # Manuelle, Automatique
    'Origine',             # WW au Maroc, ImportÃ©e
    'PremiÃ¨re main',       # Oui, Non
    'Ã‰tat',                # Excellent, TrÃ¨s bon, Bon, Correct
    'Ville',               # Localisation gÃ©ographique
    'Nombre de portes'     # 2, 3, 4, 5 portes
]

# Encodage avec LabelEncoder
from sklearn.preprocessing import LabelEncoder
encoders = {}
for col in categorical_features:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    encoders[col] = le

# Sauvegarde des encoders
joblib.dump(encoders, 'models/encoders.pkl')
```

#### Features Binaires (15)
```python
binary_features = [
    'Jantes aluminium', 'Airbags', 'Climatisation',
    'SystÃ¨me de navigation/GPS', 'Toit ouvrant', 'SiÃ¨ges cuir',
    'Radar de recul', 'CamÃ©ra de recul', 'Vitres Ã©lectriques',
    'ABS', 'ESP', 'RÃ©gulateur de vitesse', 'Limiteur de vitesse',
    'CD/MP3/Bluetooth', 'Ordinateur de bord',
    'Verrouillage centralisÃ© Ã  distance'
]
# Valeurs: 0 (non Ã©quipÃ©) ou 1 (Ã©quipÃ©)
```

**Total: 27 features** (3 numÃ©riques + 9 catÃ©gorielles + 15 binaires)

#### Normalisation (StandardScaler)

```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Formule: z = (x - Î¼) / Ïƒ
# Î¼ = moyenne, Ïƒ = Ã©cart-type

# Sauvegarde du scaler
joblib.dump(scaler, 'models/scaler.pkl')
```

### 4. EntraÃ®nement du ModÃ¨le (`train_model`)

```python
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split

# Split train/test (80/20)
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y_scaled,
    test_size=0.2,
    random_state=42
)

# Configuration du modÃ¨le (depuis params.yaml)
model = RandomForestRegressor(
    n_estimators=100,        # 100 arbres de dÃ©cision
    max_depth=20,            # Profondeur max: 20 niveaux
    min_samples_split=5,     # Min 5 Ã©chantillons pour split
    min_samples_leaf=2,      # Min 2 Ã©chantillons par feuille
    max_features='sqrt',     # âˆš27 â‰ˆ 5 features par split
    random_state=42,         # ReproductibilitÃ©
    n_jobs=-1                # Utiliser tous les CPU
)

# EntraÃ®nement
model.fit(X_train, y_train)

# RÃ©sultats:
# - Train set: 6,019 samples
# - Test set: 1,505 samples
```

### 5. Ã‰valuation (`evaluate`)

```python
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

# PrÃ©dictions
y_train_pred = model.predict(X_train)
y_test_pred = model.predict(X_test)

# MÃ©triques d'entraÃ®nement
train_r2 = r2_score(y_train, y_train_pred)      # 0.8689 (86.89%)
train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))

# MÃ©triques de test
test_r2 = r2_score(y_test, y_test_pred)         # 0.7299 (72.99%)
test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))  # 0.5188
test_mae = mean_absolute_error(y_test, y_test_pred)           # 0.3872
```

**InterprÃ©tation**:
- **RÂ² Test = 0.73**: Le modÃ¨le explique 73% de la variance des prix
- **RMSE = 0.52**: Erreur quadratique moyenne (sur prix normalisÃ©s)
- **MAE = 0.39**: Erreur absolue moyenne (sur prix normalisÃ©s)
- **LÃ©gÃ¨re sur-apprentissage**: RÂ² train (0.87) > RÂ² test (0.73), mais acceptable

### 6. Sauvegarde et Logging MLflow

```python
import mlflow
import mlflow.sklearn

with mlflow.start_run():
    # Log des paramÃ¨tres
    mlflow.log_param("n_estimators", 100)
    mlflow.log_param("max_depth", 20)
    mlflow.log_param("min_samples_split", 5)
    mlflow.log_param("train_samples", len(X_train))
    mlflow.log_param("test_samples", len(X_test))
    
    # Log des mÃ©triques
    mlflow.log_metric("train_r2", train_r2)
    mlflow.log_metric("test_r2", test_r2)
    mlflow.log_metric("test_rmse", test_rmse)
    mlflow.log_metric("test_mae", test_mae)
    
    # Log des artifacts
    mlflow.log_artifact("artifacts/feature_importance.png")
    mlflow.log_artifact("artifacts/predictions_plot.png")
    mlflow.log_artifact("artifacts/residuals_plot.png")
    
    # Enregistrement du modÃ¨le dans MLflow Registry
    mlflow.sklearn.log_model(
        sk_model=model,
        artifact_path="model",
        registered_model_name="CarPricePredictor"
    )
    
    run_id = mlflow.active_run().info.run_id
```

### Artifacts GÃ©nÃ©rÃ©s

```
artifacts/
â”œâ”€â”€ feature_importance.png      # Barplot des 15 features les plus importantes
â”œâ”€â”€ feature_importance.csv      # DonnÃ©es brutes importance
â”œâ”€â”€ predictions_plot.png        # Scatter: PrÃ©dictions vs Valeurs rÃ©elles
â”œâ”€â”€ residuals_plot.png          # Distribution des rÃ©sidus (erreurs)
â”œâ”€â”€ feature_info.json           # MÃ©tadonnÃ©es: noms, types, encodings
â””â”€â”€ price_scaler_info.json      # ParamÃ¨tres du scaler de prix (Î¼, Ïƒ)

models/
â”œâ”€â”€ car_model.pkl               # ModÃ¨le RandomForest entraÃ®nÃ©
â”œâ”€â”€ scaler.pkl                  # StandardScaler pour features
â””â”€â”€ encoders.pkl                # Dict de LabelEncoders
```

### Option 1: Lancer l'application Streamlit (RecommandÃ©)

```bash
streamlit run main_mlflow.py
```

L'application s'ouvrira Ã  `http://localhost:8501`

**FonctionnalitÃ©s de l'app:**
- ğŸ¯ Formulaire pour entrer les caractÃ©ristiques du vÃ©hicule
- ğŸ’° PrÃ©diction du prix en DH marocain
- ğŸ“Š Visualisations des features importance
- ğŸ“ˆ Historique des prÃ©dictions

### Option 2: Utiliser le modÃ¨le en Python

```python
import joblib
import pandas as pd
import json
from sklearn.preprocessing import LabelEncoder

# Charger les artifacts
model = joblib.load('models/car_model.pkl')
scaler = joblib.load('models/scaler.pkl')

with open('artifacts/feature_info.json', 'r') as f:
    feature_info = json.load(f)

with open('artifacts/price_scaler_info.json', 'r') as f:
    price_scaler_info = json.load(f)

# CrÃ©er les encodeurs et prÃ©parer les donnÃ©es
# [Voir CODE_EXAMPLES.md pour l'exemple complet]

# Faire une prÃ©diction
prediction = model.predict(X_scaled)
```

### Option 3: RÃ©entraÃ®ner le modÃ¨le

#### Avec DVC:
```bash
dvc repro -f dvc/dvc.yaml
```

#### Ou directement:
```bash
python scripts/train_with_mlflow.py
```

### Option 4: Lancer les tests

```bash
pytest tests/ -v
pytest tests/ --cov=.  # Avec coverage
```

## ğŸ”„ Pipeline de donnÃ©es

### Ã‰tapes du pipeline:

1. **Chargement** (`load_data`)
   - Lecture du CSV Avito Maroc
   - Encodage: latin1

2. **Nettoyage** (`preprocess_data`)
   - Imputation des valeurs manquantes
   - Suppression des doublons
   - Suppression des colonnes corrÃ©lÃ©es

3. **Encodage** (`encode_features`)
   - Label encoding pour variables catÃ©goriques
   - OneHot encoding optionnel

4. **Normalisation** (`scale_features`)
   - StandardScaler pour features numÃ©riques

5. **EntraÃ®nement** (`train_model`)
   - Random Forest Regressor
   - HyperparamÃ¨tres optimisÃ©s

6. **Ã‰valuation** (`evaluate`)
   - MAE, MSE, RÂ² Score
   - Sauvegarde avec MLflow

### Configuration du pipeline

Voir `params.yaml`:
```yaml
train:
  test_size: 0.2
  random_state: 42
model:
  n_estimators: 100
  max_depth: 20
  min_samples_split: 5
  min_samples_leaf: 2
  max_features: 'sqrt'
```

## ğŸ“Š RÃ©sultats du modÃ¨le

Le modÃ¨le Random Forest entraÃ®nÃ© achieves:
- **RÂ² Score**: ~0.87
- **MAE (Mean Absolute Error)**: Environ 15-20% du prix moyen
- **DonnÃ©es**: 10,000+ vÃ©hicules Avito Maroc

### Features importantes:
1. KilomÃ©trage
2. AnnÃ©e-ModÃ¨le
3. Marque du vÃ©hicule
4. Ã‰tat gÃ©nÃ©ral
5. Puissance fiscale

## ğŸ“ Structure du projet

```
detection_car_price/
â”œâ”€â”€ README.md                      # Ce fichier
â”œâ”€â”€ requirements/requirements.txt               # DÃ©pendances pip
â”œâ”€â”€ requirements/requirements-dev.txt           # DÃ©pendances dÃ©veloppement
â”œâ”€â”€ params.yaml                    # HyperparamÃ¨tres du modÃ¨le
â”œâ”€â”€ dvc/dvc.yaml                               # Pipeline DVC
â”œâ”€â”€ pytest.ini                     # Configuration pytest
â”‚
â”œâ”€â”€ data/raw/avito_car_dataset_ALL.csv      # Dataset source
â”œâ”€â”€ main.py                        # App Streamlit basique
â”œâ”€â”€ main_mlflow.py                 # App Streamlit avec MLflow
â”œâ”€â”€ scripts/train_with_mlflow.py   # Pipeline d'entraÃ®nement
â”œâ”€â”€ finalpreoject.py               # Analyse EDA
â”œâ”€â”€ scripts/load_model_mlflow.py   # Chargement des modÃ¨les
â”‚
â”œâ”€â”€ tests/                         # Suite de tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_pipeline.py
â”‚   â”œâ”€â”€ test_integration.py
â”‚   â””â”€â”€ test_car_pipeline.py
â”‚
â”œâ”€â”€ mlflow/mlruns/                 # Artifacts MLflow
â”‚   â”œâ”€â”€ 1/                         # Experiment 1
â”‚   â”œâ”€â”€ 710723541858247182/        # Experiment 2
â”‚   â””â”€â”€ models/                    # Registered Models
â”‚
â”œâ”€â”€ reports/htmlcov/               # Coverage reports
â””â”€â”€ __pycache__/                   # Cache Python
```

## ğŸ› ï¸ Technologies utilisÃ©es

### Data & ML:
- **pandas** - Manipulation de donnÃ©es
- **NumPy** - Calculs numÃ©riques
- **scikit-learn** - Machine Learning
- **joblib** - SÃ©rialisation de modÃ¨les

### MLOps:
- **MLflow** - Tracking d'expÃ©riences et versioning
- **DVC** - Gestion de donnÃ©es et pipelines

### Frontend:
- **Streamlit** - Interface web interactive

### Visualisation:
- **matplotlib** - Graphiques
- **seaborn** - Visualisations avancÃ©es
- **ydata-profiling** - Rapports EDA

### DevOps & Tests:
- **pytest** - Framework de test
- **PyYAML** - Gestion de fichiers YAML
- **skops** - SÃ©rialisation scikit-learn

## ğŸ“ˆ MÃ©triques MLflow

Les expÃ©riences sont trackÃ©es dans MLflow. Pour visualiser le dashboard:

```bash
mlflow ui
```

Puis accÃ©dez Ã  `http://localhost:5000`

Vous verrez:
- Historique des entraÃ®nements
- Comparaison des mÃ©triques
- ParamÃ¨tres utilisÃ©s
- Artifacts (modÃ¨les, scalers)

## ğŸ§ª Tests

```bash
# Lancer tous les tests
pytest tests/ -v

# Tests avec coverage
pytest tests/ --cov=. --cov-report=html

# Tests spÃ©cifiques
pytest tests/test_pipeline.py -v
pytest tests/test_integration.py -v
```

## ğŸ“š Documentation supplÃ©mentaire

- Voir [CODE_EXAMPLES.md](CODE_EXAMPLES.md) pour des exemples d'utilisation dÃ©taillÃ©s
- Rapport de profiling: [reports/profiling_rep.html](reports/profiling_rep.html)
- Coverage report: [reports/htmlcov/index.html](reports/htmlcov/index.html)

## ğŸ” Analyse EDA

Un rapport complet de l'analyse exploratoire est gÃ©nÃ©rÃ© dans `reports/profiling_rep.html`:

```bash
# RÃ©gÃ©nÃ©rer le rapport (optionnel)
python finalpreoject.py
```

Contient:
- Statistiques descriptives
- Distribution des variables
- CorrÃ©lations entre features
- DÃ©tection d'anomalies
- Valeurs manquantes

## ğŸ› Troubleshooting

### Airflow crashe avec erreurs SIGSEGV

**Diagnostic**: Ce bug affecte **macOS ARM64 uniquement** (M1/M2/M3), toutes versions Python.

**Root Cause**: Gunicorn + macOS ARM64 incompatibilitÃ© (problÃ¨me connu upstream).

**Solution dÃ©finitive**: Utiliser Docker (voir section Airflow ci-dessus).

**Tentatives infructueuses documentÃ©es:**
- âŒ Migration Python 3.12 â†’ 3.11 : N'a pas rÃ©solu le problÃ¨me
- âŒ Configuration webserver_config.py avec workers sync : Ã‰chec
- âŒ Variables d'environnement GUNICORN_CMD_ARGS : Sans effet

**Verdict**: Airflow n'est actuellement **pas supportÃ© nativement** sur macOS ARM64.

**Solution**: Migrer vers Python 3.11
```bash
# Voir le guide complet
cat PYTHON_3.11_MIGRATION.md

# Migration express
brew install python@3.11
rm -rf .venv
python3.11 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

**Alternatives**:
- Docker: `docker run -p 8080:8080 apache/airflow:2.8.1 standalone`
- DÃ©ploiement Linux/Cloud

Documentation complÃ¨te: [PYTHON_3.11_MIGRATION.md](PYTHON_3.11_MIGRATION.md)

### L'app Streamlit ne dÃ©marre pas

```bash
# VÃ©rifier les dÃ©pendances
pip install -r requirements/requirements.txt

# RÃ©installer en cas de problÃ¨me
pip install --force-reinstall -r requirements/requirements.txt
```

### ModÃ¨le non trouvÃ©

Assurez-vous d'avoir entraÃ®nÃ© le modÃ¨le:
```bash
python scripts/train_with_mlflow.py
# ou
dvc repro -f dvc/dvc.yaml
```

### Erreurs d'encodage CSV

Le dataset utilise l'encodage `latin1`. Ne le changez pas.

### VÃ©rifier la version Python

```bash
# Dans le projet
python --version  # Doit afficher 3.11.x pour Airflow

# Changer de version avec pyenv
pyenv versions  # Lister les versions disponibles
pyenv local 3.11.7  # Utiliser 3.11 pour ce projet
```

## ğŸ¤ Contribution

Les contributions sont bienvenues! Pour contribuer:

1. Fork le repository
2. CrÃ©er une branche feature (`git checkout -b feature/AmazingFeature`)
3. Commit vos changements (`git commit -m 'Add some AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrir une Pull Request

## ğŸ“ License

Ce projet est open source et disponible sous la licence MIT.

## âš ï¸ PrÃ©requis Airflow

**Apache Airflow nÃ©cessite Python 3.11 sur macOS.**

Si vous utilisez Python 3.12, suivez le guide de migration:
```bash
# Guide complet de migration
cat PYTHON_3.11_MIGRATION.md

# Migration rapide (15 min)
brew install python@3.11
rm -rf .venv
python3.11 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

Voir: [PYTHON_3.11_MIGRATION.md](PYTHON_3.11_MIGRATION.md)

### ğŸ³ Stack MLOps ComplÃ¨te avec Docker

**Solution professionnelle : Tous les services dans Docker**

Cette stack intÃ¨gre MLflow, Streamlit, Airflow et PostgreSQL dans des containers isolÃ©s.

**DÃ©marrage rapide:**
```bash
# DÃ©marrer toute la stack (MLflow + Streamlit + Airflow)
./docker-start-full.sh

# ArrÃªter la stack
./docker-stop-full.sh

# RÃ©initialiser complÃ¨tement (si problÃ¨mes)
./docker-reset-full.sh
```

**Services disponibles:**
- **MLflow**: http://localhost:5000 - Tracking d'expÃ©riences
- **Streamlit**: http://localhost:8501 - Interface de prÃ©diction
- **Airflow**: http://localhost:8080 - Orchestration (admin / admin)

**Avantages Docker:**
- âœ… Isolation complÃ¨te des services
- âœ… ReproductibilitÃ© garantie
- âœ… Pas de conflits de dÃ©pendances
- âœ… Production-ready
- âœ… Fonctionne sur macOS ARM64 (M1/M2/M3)

**Commandes utiles:**
```bash
# Voir les logs en temps rÃ©el
docker compose -f docker-compose-full.yml logs -f

# Logs d'un service spÃ©cifique
docker compose -f docker-compose-full.yml logs -f streamlit
docker compose -f docker-compose-full.yml logs -f mlflow
docker compose -f docker-compose-full.yml logs -f airflow-webserver

# Statut des services
docker compose -f docker-compose-full.yml ps

# RedÃ©marrer un service
docker compose -f docker-compose-full.yml restart streamlit
```

**Interface Web**: http://localhost:8080 (consulter le terminal pour les identifiants)

**Alternative - Mode sÃ©parÃ©:**
```bash
# Terminal 1 - Scheduler
export AIRFLOW_HOME=$(pwd)/airflow
airflow scheduler

# Tester sans interface web
airflow dags test car_price_predictor_pipeline $(date +%Y-%m-%d)
```

### Pipeline AutomatisÃ©

Le DAG `car_price_predictor_pipeline` exÃ©cute automatiquement:

1. âœ… **VÃ©rification donnÃ©es** - QualitÃ© et volume
2. ğŸš€ **EntraÃ®nement** - Model training avec MLflow
3. ğŸ“Š **Ã‰valuation** - MÃ©triques RÂ² et RMSE
4. ğŸ“¦ **Staging** - Promotion si critÃ¨res OK (RÂ²>0.80, RMSE<50k)
5. ğŸ§ª **Validation** - Tests en Staging
6. ğŸ¯ **Production** - DÃ©ploiement automatique
7. ğŸ“§ **Rapport** - GÃ©nÃ©ration rapport JSON

**Planification**: Hebdomadaire (modifiable dans le DAG)

Voir la documentation complÃ¨te: [airflow/README_AIRFLOW.md](airflow/README_AIRFLOW.md)

---

## ğŸ¯ Objectifs futurs

- [x] Pipeline MLOps avec Airflow
- [ ] DÃ©ploiement sur cloud (AWS/GCP/Azure)
- [ ] API REST avec FastAPI
- [ ] Dashboard de monitoring
- [ ] A/B testing de modÃ¨les
- [ ] PrÃ©dictions batch
- [ ] Explainability avec SHAP

---

**DerniÃ¨re mise Ã  jour**: FÃ©vrier 2026  
**Version**: 1.1.0 (avec Airflow)
