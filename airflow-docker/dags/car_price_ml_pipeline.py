"""
Airflow DAG pour le pipeline MLOps CarPricePredictor
Orchestration de l'entraÃ®nement, Ã©valuation et promotion des modÃ¨les
"""
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.operators.email import EmailOperator
from airflow.sensors.filesystem import FileSensor
from datetime import datetime, timedelta
import sys
import os

# Ajouter le chemin du projet au PYTHONPATH
project_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '../..'))
sys.path.insert(0, project_path)

# Configuration par dÃ©faut du DAG
default_args = {
    'owner': 'data-science-team',
    'depends_on_past': False,
    'start_date': datetime(2026, 2, 14),
    'email': ['alerts@example.com'],
    'email_on_failure': True,
    'email_on_retry': False,
    'retries': 2,
    'retry_delay': timedelta(minutes=5),
}

# DÃ©finition du DAG
dag = DAG(
    'car_price_predictor_pipeline',
    default_args=default_args,
    description='Pipeline ML complet pour la prÃ©diction de prix de voitures',
    schedule_interval='@weekly',  # ExÃ©cution hebdomadaire
    catchup=False,
    tags=['machine-learning', 'mlflow', 'car-price'],
)


def check_data_quality(**context):
    """VÃ©rifier la qualitÃ© des donnÃ©es avant l'entraÃ®nement"""
    import pandas as pd
    import mlflow
    
    print("ðŸ“Š VÃ©rification de la qualitÃ© des donnÃ©es...")
    
    # Chargement des donnÃ©es
    data_path = os.path.join(project_path, 'data/raw/avito_car_dataset_ALL.csv')
    df = pd.read_csv(data_path, encoding='latin1')
    
    # Calculs de qualitÃ©
    total_rows = len(df)
    missing_values = df.isnull().sum().sum()
    missing_percentage = (missing_values / (total_rows * len(df.columns))) * 100
    
    # VÃ©rifications
    quality_checks = {
        'total_rows': total_rows,
        'missing_percentage': missing_percentage,
        'columns': list(df.columns),
        'data_ok': total_rows > 1000 and missing_percentage < 50
    }
    
    print(f"âœ… Lignes: {total_rows}")
    print(f"âœ… Valeurs manquantes: {missing_percentage:.2f}%")
    
    # Sauvegarder dans XCom pour les tÃ¢ches suivantes
    context['ti'].xcom_push(key='data_quality', value=quality_checks)
    
    if not quality_checks['data_ok']:
        raise ValueError("âŒ DonnÃ©es insuffisantes pour l'entraÃ®nement")
    
    return quality_checks


def train_model(**context):
    """EntraÃ®ner le modÃ¨le avec MLflow"""
    import mlflow
    from scripts.train_with_mlflow import CarPricePipeline
    
    print("ðŸš€ DÃ©marrage de l'entraÃ®nement du modÃ¨le...")
    
    # Configuration MLflow
    mlflow_path = os.path.join(project_path, 'mlflow', 'mlruns')
    mlflow.set_tracking_uri(f"file:{mlflow_path}")
    mlflow.set_experiment("car_price_prediction")
    
    # RÃ©cupÃ©rer les infos de qualitÃ© des donnÃ©es
    data_quality = context['ti'].xcom_pull(key='data_quality', task_ids='check_data_quality')
    print(f"ðŸ“Š DonnÃ©es validÃ©es: {data_quality['total_rows']} lignes")
    
    # EntraÃ®nement
    with mlflow.start_run(run_name=f"airflow_training_{datetime.now().strftime('%Y%m%d_%H%M%S')}"):
        # Tag pour identifier les runs Airflow
        mlflow.set_tag("pipeline", "airflow")
        mlflow.set_tag("trigger", "scheduled")
        
        pipeline = CarPricePipeline()
        
        # Load and prepare data
        df = pipeline.load_data()
        X_train, X_test, y_train, y_test = pipeline.prepare_data(df)
        
        # Train model
        pipeline.train_model(X_train, y_train)
        
        # Evaluate
        metrics = pipeline.evaluate_model(X_test, y_test)
        
        # Log artifacts
        pipeline.save_artifacts()
        
        # Get run ID
        run_id = mlflow.active_run().info.run_id
        
        print(f"âœ… ModÃ¨le entraÃ®nÃ© - Run ID: {run_id}")
        print(f"ðŸ“Š RÂ² Score: {metrics['r2_score']:.4f}")
        print(f"ðŸ“Š RMSE: {metrics['rmse']:.2f}")
        
        # Sauvegarder les infos dans XCom
        context['ti'].xcom_push(key='run_id', value=run_id)
        context['ti'].xcom_push(key='metrics', value=metrics)
    
    return run_id


def evaluate_model(**context):
    """Ã‰valuer le modÃ¨le et dÃ©cider de la promotion"""
    import mlflow
    from mlflow.tracking import MlflowClient
    
    print("ðŸ” Ã‰valuation du modÃ¨le...")
    
    # Configuration MLflow
    mlflow_path = os.path.join(project_path, 'mlflow', 'mlruns')
    mlflow.set_tracking_uri(f"file:{mlflow_path}")
    
    # RÃ©cupÃ©rer les mÃ©triques
    run_id = context['ti'].xcom_pull(key='run_id', task_ids='train_model')
    metrics = context['ti'].xcom_pull(key='metrics', task_ids='train_model')
    
    # CritÃ¨res de qualitÃ©
    MINIMUM_R2 = 0.80  # RÂ² minimum acceptable
    MAXIMUM_RMSE = 50000  # RMSE maximum acceptable
    
    r2_score = metrics['r2_score']
    rmse = metrics['rmse']
    
    print(f"ðŸ“Š RÂ² Score: {r2_score:.4f} (min: {MINIMUM_R2})")
    print(f"ðŸ“Š RMSE: {rmse:.2f} (max: {MAXIMUM_RMSE})")
    
    # DÃ©cision
    is_promotable = r2_score >= MINIMUM_R2 and rmse <= MAXIMUM_RMSE
    
    evaluation_result = {
        'run_id': run_id,
        'r2_score': r2_score,
        'rmse': rmse,
        'is_promotable': is_promotable,
        'evaluation_date': datetime.now().isoformat()
    }
    
    if is_promotable:
        print("âœ… ModÃ¨le Ã©ligible pour la promotion!")
    else:
        print("âš ï¸ ModÃ¨le ne satisfait pas les critÃ¨res de qualitÃ©")
    
    context['ti'].xcom_push(key='evaluation_result', value=evaluation_result)
    
    return evaluation_result


def promote_to_staging(**context):
    """Promouvoir le modÃ¨le vers Staging"""
    import mlflow
    from mlflow.tracking import MlflowClient
    
    print("ðŸ“¦ Promotion du modÃ¨le vers Staging...")
    
    # Configuration MLflow
    mlflow_path = os.path.join(project_path, 'mlflow', 'mlruns')
    mlflow.set_tracking_uri(f"file:{mlflow_path}")
    client = MlflowClient()
    
    # RÃ©cupÃ©rer les rÃ©sultats d'Ã©valuation
    eval_result = context['ti'].xcom_pull(key='evaluation_result', task_ids='evaluate_model')
    
    if not eval_result['is_promotable']:
        print("âš ï¸ ModÃ¨le non Ã©ligible, promotion annulÃ©e")
        return "skipped"
    
    run_id = eval_result['run_id']
    model_name = "CarPricePredictor"
    
    try:
        # Enregistrer le modÃ¨le
        model_uri = f"runs:/{run_id}/model"
        model_version = mlflow.register_model(model_uri, model_name)
        
        # Promouvoir vers Staging
        client.transition_model_version_stage(
            name=model_name,
            version=model_version.version,
            stage="Staging",
            archive_existing_versions=False
        )
        
        print(f"âœ… ModÃ¨le promu vers Staging - Version {model_version.version}")
        
        context['ti'].xcom_push(key='model_version', value=model_version.version)
        
        return model_version.version
        
    except Exception as e:
        print(f"âŒ Erreur lors de la promotion: {str(e)}")
        raise


def validate_staging_model(**context):
    """Valider le modÃ¨le en Staging avant production"""
    import mlflow
    from mlflow.tracking import MlflowClient
    import pandas as pd
    import numpy as np
    
    print("ðŸ§ª Validation du modÃ¨le en Staging...")
    
    # Configuration MLflow
    mlflow_path = os.path.join(project_path, 'mlflow', 'mlruns')
    mlflow.set_tracking_uri(f"file:{mlflow_path}")
    client = MlflowClient()
    
    model_name = "CarPricePredictor"
    model_version = context['ti'].xcom_pull(key='model_version', task_ids='promote_to_staging')
    
    # Charger le modÃ¨le depuis Staging
    model_uri = f"models:/{model_name}/Staging"
    model = mlflow.sklearn.load_model(model_uri)
    
    # Test sur quelques prÃ©dictions
    # CrÃ©er des donnÃ©es de test simples
    test_data = pd.DataFrame({
        'year': [2020, 2015, 2018],
        'brand': [1, 2, 3],
        'fuel_type': [1, 2, 1],
        'transmission': [1, 0, 1],
    })
    
    # Faire des prÃ©dictions
    predictions = model.predict(test_data)
    
    # VÃ©rifications basiques
    validation_checks = {
        'model_loaded': True,
        'predictions_valid': all(predictions > 0),
        'predictions_reasonable': all(predictions < 1000000),  # Prix < 1M
        'model_version': model_version,
        'validation_passed': True
    }
    
    print(f"âœ… Validation rÃ©ussie - Version {model_version}")
    print(f"ðŸ“Š PrÃ©dictions test: {predictions[:3]}")
    
    context['ti'].xcom_push(key='validation_checks', value=validation_checks)
    
    return validation_checks


def promote_to_production(**context):
    """Promouvoir le modÃ¨le vers Production"""
    import mlflow
    from mlflow.tracking import MlflowClient
    
    print("ðŸš€ Promotion du modÃ¨le vers Production...")
    
    # Configuration MLflow
    mlflow_path = os.path.join(project_path, 'mlflow', 'mlruns')
    mlflow.set_tracking_uri(f"file:{mlflow_path}")
    client = MlflowClient()
    
    # RÃ©cupÃ©rer la version du modÃ¨le
    model_version = context['ti'].xcom_pull(key='model_version', task_ids='promote_to_staging')
    validation = context['ti'].xcom_pull(key='validation_checks', task_ids='validate_staging_model')
    
    if not validation['validation_passed']:
        print("âš ï¸ Validation Ã©chouÃ©e, promotion vers Production annulÃ©e")
        return "skipped"
    
    model_name = "CarPricePredictor"
    
    try:
        # Archiver les versions Production actuelles
        client.transition_model_version_stage(
            name=model_name,
            version=model_version,
            stage="Production",
            archive_existing_versions=True
        )
        
        print(f"âœ… ModÃ¨le promu vers Production - Version {model_version}")
        
        return {
            'model_name': model_name,
            'version': model_version,
            'stage': 'Production',
            'promotion_date': datetime.now().isoformat()
        }
        
    except Exception as e:
        print(f"âŒ Erreur lors de la promotion Production: {str(e)}")
        raise


def send_pipeline_report(**context):
    """GÃ©nÃ©rer et envoyer un rapport du pipeline"""
    import json
    
    print("ðŸ“§ GÃ©nÃ©ration du rapport de pipeline...")
    
    # RÃ©cupÃ©rer toutes les informations
    data_quality = context['ti'].xcom_pull(key='data_quality', task_ids='check_data_quality')
    run_id = context['ti'].xcom_pull(key='run_id', task_ids='train_model')
    metrics = context['ti'].xcom_pull(key='metrics', task_ids='train_model')
    eval_result = context['ti'].xcom_pull(key='evaluation_result', task_ids='evaluate_model')
    
    # CrÃ©er le rapport
    report = {
        'pipeline_date': datetime.now().isoformat(),
        'data_quality': data_quality,
        'training': {
            'run_id': run_id,
            'metrics': metrics
        },
        'evaluation': eval_result,
        'status': 'SUCCESS'
    }
    
    # Sauvegarder le rapport
    report_path = os.path.join(project_path, 'reports', f"pipeline_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
    os.makedirs(os.path.dirname(report_path), exist_ok=True)
    
    with open(report_path, 'w') as f:
        json.dump(report, f, indent=2)
    
    print(f"âœ… Rapport sauvegardÃ©: {report_path}")
    print(f"ðŸ“Š Status: {report['status']}")
    print(f"ðŸ“Š RÂ² Score: {metrics['r2_score']:.4f}")
    
    return report


# ========================================
# DÃ©finition des tÃ¢ches
# ========================================

# TÃ¢che 1: VÃ©rification de la qualitÃ© des donnÃ©es
check_data = PythonOperator(
    task_id='check_data_quality',
    python_callable=check_data_quality,
    dag=dag,
)

# TÃ¢che 2: EntraÃ®nement du modÃ¨le
train = PythonOperator(
    task_id='train_model',
    python_callable=train_model,
    dag=dag,
)

# TÃ¢che 3: Ã‰valuation du modÃ¨le
evaluate = PythonOperator(
    task_id='evaluate_model',
    python_callable=evaluate_model,
    dag=dag,
)

# TÃ¢che 4: Promotion vers Staging
staging = PythonOperator(
    task_id='promote_to_staging',
    python_callable=promote_to_staging,
    dag=dag,
)

# TÃ¢che 5: Validation du modÃ¨le en Staging
validate = PythonOperator(
    task_id='validate_staging_model',
    python_callable=validate_staging_model,
    dag=dag,
)

# TÃ¢che 6: Promotion vers Production
production = PythonOperator(
    task_id='promote_to_production',
    python_callable=promote_to_production,
    dag=dag,
)

# TÃ¢che 7: Rapport final
report = PythonOperator(
    task_id='send_pipeline_report',
    python_callable=send_pipeline_report,
    dag=dag,
)

# ========================================
# DÃ©finition du flux de tÃ¢ches
# ========================================

check_data >> train >> evaluate >> staging >> validate >> production >> report
